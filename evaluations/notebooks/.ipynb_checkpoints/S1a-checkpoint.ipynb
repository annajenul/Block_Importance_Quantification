{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulation S1a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'src.multiblock_network'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-ed669603b06a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/home/anna/GitHub/Block_Importance_Quantification\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultiblock_network\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmultiblock_network\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhelp_functions\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mhelp_functions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhelp_functions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mremove_outliers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'src.multiblock_network'"
     ]
    }
   ],
   "source": [
    "from operator import pos\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import time\n",
    "\n",
    "import os\n",
    "os.chdir(\"/home/anna/GitHub/Block_Importance_Quantification\")\n",
    "from src.multiblock_network import multiblock_network\n",
    "import src.help_functions as help_functions\n",
    "from src.help_functions import remove_outliers\n",
    "\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import Sequential, optimizers\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set a seed to get reproducible results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the data and create the 8 blocks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv(\"data/simulation/X_train.csv\").iloc[:,1:]\n",
    "X_test = pd.read_csv(\"data/simulation/X_test.csv\").iloc[:,1:]\n",
    "y_train = pd.read_csv(\"data/simulation/y_train_S1a.csv\").iloc[:,1:]\n",
    "y_test = pd.read_csv(\"data/simulation/y_test_S1a.csv\").iloc[:,1:]\n",
    "beta = pd.read_csv(\"data/simulation/beta_S1a.csv\").iloc[:,1:].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_blocks = []\n",
    "data_blocks_test = []\n",
    "beta_blocks = []\n",
    "j=0\n",
    "for i in range(8):\n",
    "    data_blocks.append(X_train.iloc[:,j:(j+32)])\n",
    "    data_blocks_test.append(X_test.iloc[:,j:(j+32)])\n",
    "    beta_blocks.append(beta[j:(j+32)])\n",
    "    j = j+32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_nodes_concat = 4\n",
    "\n",
    "def build_block_network(data, activation=\"elu\", learning_rate=0.1, prob = \"class\", epochs=1000):\n",
    "    network = multiblock_network()\n",
    "    \n",
    "    # blockwise network\n",
    "    for b in data:\n",
    "            structure1 = [Input(shape=(np.shape(b)[1],)),\n",
    "                  Dense(16, activation=activation),\n",
    "                  Dense(8, activation=activation),\n",
    "                  Dense(num_nodes_concat, activation=activation)]\n",
    "            network.define_block_net(structure1.copy())\n",
    "    # blender network\n",
    "    structure = [Dense(2, activation=activation),\n",
    "                 Dense(2, activation=activation),\n",
    "                 Dense(1, activation=\"linear\")]\n",
    "    #concatenate\n",
    "    network.define_block_concatenation(structure=structure)\n",
    "\n",
    "    opt = tf.keras.optimizers.RMSprop()\n",
    "\n",
    "\n",
    "    if prob ==\"class\":\n",
    "        network.compile(loss=\"binary_crossentropy\", optimizer=opt,\n",
    "                       metrics=[help_functions.matthews_correlation, help_functions.f1_m])\n",
    "    elif prob == \"regression\":\n",
    "        network.compile(loss='mean_squared_error', optimizer=opt,\n",
    "                        metrics=[help_functions.coeff_determination])\n",
    "\n",
    "    return network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network parameters that were evaluated in advance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "epochs = 100\n",
    "learning_rate = 1\n",
    "activation = 'relu'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scale the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_blocks_sc = []\n",
    "data_blocks_test_sc = []\n",
    "\n",
    "for i in range(len(data_blocks)):\n",
    "    sc = StandardScaler()\n",
    "    data_blocks_sc.append(sc.fit_transform(data_blocks[i]))\n",
    "    data_blocks_test_sc.append(sc.transform(data_blocks_test[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train 30 different model and evaluate the metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_list(num):\n",
    "        return [None for _ in range(num)]\n",
    "\n",
    "\n",
    "n = 30\n",
    "\n",
    "# metrics\n",
    "rmseiqr = create_list(n)\n",
    "rmse_q1 = np.quantile(y_test, 0.25)\n",
    "rmse_q3 = np.quantile(y_test, 0.75)\n",
    "\n",
    "r2 = create_list(n)\n",
    "\n",
    "KI = create_list(n)\n",
    "KO = create_list(n)\n",
    "\n",
    "vargrad_max = create_list(n)\n",
    "vargrad_mean = create_list(n)\n",
    "\n",
    "time_trac = create_list(n)\n",
    "\n",
    "for i in range(n):\n",
    "    np.random.seed(i)\n",
    "    tf.random.set_seed(i)\n",
    "    \n",
    "    start = time.time()\n",
    "    network = build_block_network(data=data_blocks_sc, activation=activation,\n",
    "                                learning_rate=learning_rate, prob=\"regression\", epochs=epochs)\n",
    "\n",
    "    network.fit(data_blocks_sc, y_train, epochs=epochs, batch_size=batch_size,\n",
    "                validation_data = (data_blocks_test_sc,  y_test), verbose=0, problem=\"regression\")\n",
    "    \n",
    "    end = time.time()\n",
    "    time_trac[i] = end-start\n",
    "    \n",
    "    pred = network.predict(data_blocks_test_sc)\n",
    "    rmseiqr[i] = (mean_squared_error(y_test, pred, squared=False)/(rmse_q3-rmse_q1))\n",
    "    r2[i] = r2_score(y_test, pred)\n",
    "    \n",
    "    l = 10 # number of bins\n",
    "    KI[i] = network.MI(data_blocks_sc, type=\"mean\", eps=1e-100, bins=l, knock_out=False, on_input=False,\n",
    "                        density=True, plot=False)\n",
    "    \n",
    "    KO[i] = np.log2(l) - network.MI(data_blocks_sc, type=\"mean\", eps=1e-100, bins=l, knock_out=True, on_input=False,\n",
    "                         density=True, plot=False)\n",
    "\n",
    "\n",
    "    vargrad_max[i] = network.vargrad_input(data_blocks_sc, type=\"max\", seed=i)\n",
    "    vargrad_mean[i] = network.vargrad_input(data_blocks_sc, type=\"mean\", seed=i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"average runtime:\", np.round(np.mean(time_trac)), \"seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import plot_model, model_to_dot\n",
    "plot_model(network.comb_net, \"/evaluations/figures/Simulation_M_ANN.png\", show_shapes=True, show_layer_names=True,rankdir='LR', dpi=96, expand_nested=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance and removal of badly initialized networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Mean rmseiqr:\", np.mean(rmseiqr), \"sd rmseiqr:\", np.std(rmseiqr))\n",
    "print(\"Mean R2:\", np.mean(r2), \"sd R2:\", np.std(r2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x=range(n), y = r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outliers = np.where(np.array(r2)<0.9)[0]\n",
    "outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(outliers)>=1:\n",
    "    rmseiqr = remove_outliers(rmseiqr, outliers)\n",
    "    r2 = remove_outliers(r2, outliers)\n",
    "    \n",
    "    t = []\n",
    "    for i in KO:\n",
    "        t.append(i.tolist())\n",
    "\n",
    "    KO = remove_outliers(t, outliers)\n",
    "\n",
    "    t = []\n",
    "    for i in KI:\n",
    "        t.append(i.tolist())\n",
    "\n",
    "    KI = remove_outliers(t, outliers)\n",
    "    vargrad_max = remove_outliers(vargrad_max, outliers)\n",
    "    vargrad_mean = remove_outliers(vargrad_mean, outliers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Mean rmseiqr:\", np.mean(rmseiqr), \"sd rmseiqr:\", np.std(rmseiqr))\n",
    "print(\"Mean R2:\", np.mean(r2), \"sd R2:\", np.std(r2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results as histogram-swarm plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def violinplot_block_importance(measure, name, minimize,title_text=None):\n",
    "    \n",
    "    length = np.shape(np.vstack(measure))[0]\n",
    "\n",
    "    dic = {\"Block\": list(np.repeat(\"Block1\", length)) + list(np.repeat(\"Block2\", length))\n",
    "           + list(np.repeat(\"Block3\", length))\n",
    "                 + list(np.repeat(\"Block4\", length))\n",
    "                       + list(np.repeat(\"Block5\", length))\n",
    "                             + list(np.repeat(\"Block6\", length))\n",
    "                                   + list(np.repeat(\"Block7\", length))\n",
    "                                         + list(np.repeat(\"Block8\", length)),\n",
    "                                                    name : np.column_stack(np.vstack(measure)).reshape(-1,)}\n",
    "    dic = pd.DataFrame(dic)\n",
    "\n",
    "    fig, ax =plt.subplots(1,1)\n",
    "    fig.set_size_inches(15, 10)\n",
    "    sns.set(font_scale = 2)\n",
    "\n",
    "    a = sns.boxplot(x=\"Block\", y=name, data=dic, whis=np.inf, palette=\"Paired\")\n",
    "    sns.swarmplot(x=\"Block\", y=name, data=dic, color=\".2\", size=6)\n",
    "    a.set(xlabel=None)\n",
    "    a.set(title=title_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "violinplot_block_importance(KO, \"MI knock out\", minimize=False, title_text = \"MI knock out\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "violinplot_block_importance(KI, \"MI knock in\", minimize=False, title_text = \"MI knock in\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "violinplot_block_importance(vargrad_max, \"VG max\", minimize=False, title_text = \"Composite max\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "violinplot_block_importance(vargrad_mean, \"VG mean\", minimize=False, title_text = \"Composite mean\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
